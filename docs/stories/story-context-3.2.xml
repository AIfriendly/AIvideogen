<?xml version="1.0" encoding="UTF-8"?>
<story-context>
  <metadata>
    <story-id>3.2</story-id>
    <story-name>Scene Text Analysis &amp; Search Query Generation</story-name>
    <epic>Epic 3 - Visual Content Sourcing (YouTube API)</epic>
    <status>ready</status>
    <created>2025-11-15</created>
    <agent>Dev Agent (Claude Sonnet 4.5)</agent>
    <context-generated>2025-11-15</context-generated>
    <generated-by>SM Agent (Scrum Master)</generated-by>
  </metadata>

  <story-overview>
    <goal>Analyze script scene text using LLM to extract visual themes and generate optimized YouTube search queries</goal>
    <description>
      Implement intelligent scene text analysis using the LLM provider to extract visual themes, subjects, moods, and actions
      from script scenes, then generate optimized YouTube search queries. This story creates the "intelligence layer" between
      script content and YouTube search by leveraging the existing LLM provider infrastructure (from Epic 1 Story 1.3) to
      understand scene context and translate it into effective search terms. The analyzeSceneForVisuals() function will parse
      scene narration, identify key visual elements (main subject, setting, mood, action, keywords), and generate multiple
      search query variations to maximize YouTube search relevance and result diversity. The implementation includes fallback
      logic using simple keyword extraction for LLM failures, ensuring robust operation even when the LLM provider is temporarily
      unavailable. This analysis layer is critical for Story 3.3's YouTube search quality, as well-crafted queries directly
      impact the relevance of suggested B-roll footage.
    </description>
    <business-value>
      <value>Enables intelligent visual content discovery from scene text without manual search query writing</value>
      <value>Leverages existing LLM infrastructure to minimize new dependencies</value>
      <value>Generates diverse search queries for better YouTube result coverage</value>
      <value>Handles various content types (nature, gaming, tutorials, urban) automatically</value>
      <value>Provides robust fallback mechanism for uninterrupted operation</value>
      <value>Reduces creator manual effort by automating visual sourcing research</value>
      <value>Creates foundation for high-quality B-roll suggestions in Story 3.3</value>
      <value>Ensures system resilience through keyword extraction fallback</value>
    </business-value>
  </story-overview>

  <acceptance-criteria>
    <criterion id="1" priority="critical">
      <title>Scene analysis extracts visual themes from scene text using LLM</title>
      <details>
        - analyzeSceneForVisuals() accepts scene text string as input
        - Function calls LLM provider with visual analysis prompt template
        - LLM extracts: main subject, setting, mood, action, keywords
        - Response parsed into structured SceneAnalysis object
        - Analysis completes within 5 seconds per scene (LLM performance target)
        - System prompt optimized for visual theme extraction task
        - LLM provider integration follows Epic 1 Story 1.3 patterns
      </details>
    </criterion>
    <criterion id="2" priority="critical">
      <title>Primary search query generated for most relevant YouTube results</title>
      <details>
        - Primary query focuses on main subject and key visual elements
        - Query optimized for YouTube search algorithm (4-6 keywords)
        - Query excludes filler words and focuses on concrete visual elements
        - Query format: "{main_subject} {setting} {mood/time} {action}"
        - Example: "A majestic lion roams the savanna at sunset" → "lion savanna sunset wildlife"
        - Query relevance validated against scene content
      </details>
    </criterion>
    <criterion id="3" priority="high">
      <title>Alternative search queries provide diversity (2-3 variations)</title>
      <details>
        - System generates 2-3 alternative query variations per scene
        - Alternatives use synonyms, different keyword combinations, or focus shifts
        - Variations increase result diversity and reduce over-reliance on single query
        - Example alternatives for lion scene: ["african lion sunset", "lion walking grassland golden hour"]
        - Each alternative maintains relevance to original scene content
        - Alternatives avoid complete overlap with primary query
      </details>
    </criterion>
    <criterion id="4" priority="high">
      <title>Content type hints classify scene for specialized filtering</title>
      <details>
        - LLM identifies content type category: gameplay, tutorial, nature, b-roll, documentary, urban, abstract
        - Content type used by Story 3.4 filtering logic for specialized ranking
        - Type classification accurate for common scene categories
        - Example: Lion scene → "nature documentary"
        - Gaming scenes identified as "gameplay" type
        - Tutorial/educational scenes identified as "tutorial" type
      </details>
    </criterion>
    <criterion id="5" priority="critical">
      <title>SceneAnalysis data structure returned with all extracted fields</title>
      <details>
        - Function returns structured object with typed fields:
          {
            mainSubject: string,
            setting: string,
            mood: string,
            action: string,
            keywords: string[],
            primaryQuery: string,
            alternativeQueries: string[],
            contentType: ContentType
          }
        - All fields populated (may be empty string/array if LLM cannot extract)
        - TypeScript types defined in lib/youtube/types.ts
        - Data structure consumed by Story 3.3 search function
      </details>
    </criterion>
    <criterion id="6" priority="high">
      <title>LLM analysis completes within 5 seconds per scene</title>
      <details>
        - Average LLM call latency: &lt;5 seconds (local Ollama or cloud Gemini)
        - Timeout configured at 10 seconds to handle slow responses
        - Timeout triggers fallback to keyword extraction
        - Performance logged for monitoring and optimization
        - No blocking delays for user workflow
      </details>
    </criterion>
    <criterion id="7" priority="high">
      <title>System handles various scene types accurately</title>
      <details>
        - Nature scenes: Extracts animals, landscapes, weather, time of day
        - Gaming scenes: Identifies game type, gameplay elements, perspective
        - Tutorial scenes: Identifies subject, tools, demonstration context
        - Urban scenes: Extracts locations, architecture, city elements
        - Abstract concepts: Translates concepts into visual metaphors
        - Example test cases:
          - "A player navigates through a dark forest in Minecraft" → gameplay
          - "Mix flour and eggs in a glass bowl" → tutorial
          - "The busy streets of Tokyo at night glow with neon signs" → urban
      </details>
    </criterion>
    <criterion id="8" priority="critical">
      <title>Fallback keyword extraction works when LLM unavailable</title>
      <details>
        - LLM connection failure triggers fallback keyword extraction
        - LLM timeout (&gt;10s) triggers fallback
        - Fallback extracts nouns and verbs from scene text using NLP
        - Fallback constructs basic query from top 4-5 keywords
        - Fallback returns minimal but functional SceneAnalysis object
        - Fallback allows system to continue operating without LLM
        - Fallback logs warning for monitoring LLM availability
      </details>
    </criterion>
    <criterion id="9" priority="high">
      <title>Invalid or empty LLM responses trigger retry or fallback</title>
      <details>
        - Empty LLM response (blank or whitespace) triggers single retry
        - Invalid JSON response format triggers fallback immediately
        - Response missing required fields (mainSubject, primaryQuery) triggers retry
        - After failed retry, system falls back to keyword extraction
        - Maximum 2 LLM attempts before fallback (original + 1 retry)
        - Error logged with LLM response details for debugging
        - User workflow not blocked by LLM failures
      </details>
    </criterion>
    <criterion id="10" priority="critical">
      <title>Visual search prompt template optimized for query generation</title>
      <details>
        - Prompt template stored in lib/llm/prompts/visual-search-prompt.ts
        - Prompt instructs LLM to focus on visual elements (not concepts)
        - Prompt provides examples of good vs bad query generation
        - Prompt specifies output format (JSON structure)
        - Prompt emphasizes YouTube search optimization (concrete keywords)
        - Prompt handles edge cases (abstract concepts → visual metaphors)
        - Template parameterized with scene text variable
      </details>
    </criterion>
    <criterion id="11" priority="critical">
      <title>analyzeSceneForVisuals() integrates with existing LLM provider</title>
      <details>
        - Uses getLLMProvider() factory from lib/llm/factory.ts
        - Supports both Ollama (local) and Gemini (cloud) providers
        - Provider selection based on LLM_PROVIDER environment variable
        - No provider-specific logic in scene analysis code
        - Follows same patterns as Epic 1 chat implementation
        - LLM provider errors handled consistently with other LLM calls
      </details>
    </criterion>
  </acceptance-criteria>

  <reference-implementations>
    <reference name="Epic 1 Story 1.3: LLM Provider Pattern">
      <description>Complete LLM provider abstraction infrastructure with Ollama and Gemini implementations</description>
      <file-structure>
        lib/llm/
          ├── provider.ts              # LLMProvider interface and Message types
          ├── ollama-provider.ts       # OllamaProvider implementation
          ├── gemini-provider.ts       # GeminiProvider implementation
          ├── factory.ts               # createLLMProvider() factory function
          └── prompts/
              └── default-system-prompt.ts  # DEFAULT_SYSTEM_PROMPT constant
      </file-structure>

      <interface-definition language="typescript">
        <![CDATA[
/**
 * Message structure for LLM conversations
 */
export interface Message {
  role: 'user' | 'assistant' | 'system';
  content: string;
}

/**
 * LLMProvider interface defines the contract for all LLM provider implementations
 */
export interface LLMProvider {
  /**
   * Send a chat message to the LLM and receive a response
   *
   * @param messages - Array of conversation messages
   * @param systemPrompt - Optional system prompt to prepend
   * @returns Promise resolving to the assistant's response
   * @throws Error if the LLM service is unavailable or returns an error
   */
  chat(messages: Message[], systemPrompt?: string): Promise<string>;
}
        ]]>
      </interface-definition>

      <factory-usage language="typescript">
        <![CDATA[
import { createLLMProvider } from './llm/factory';

// Factory function handles provider selection based on environment
const llm = createLLMProvider();

// Call LLM with messages array
const response = await llm.chat([
  { role: 'user', content: 'Your prompt here' }
], 'Optional system prompt');
        ]]>
      </factory-usage>

      <environment-variables>
        <variable name="LLM_PROVIDER" default="ollama" description="Provider type (ollama or gemini)" />
        <variable name="OLLAMA_BASE_URL" default="http://localhost:11434" description="Ollama server URL (for ollama provider)" />
        <variable name="OLLAMA_MODEL" default="llama3.2" description="Ollama model name (for ollama provider)" />
        <variable name="GEMINI_API_KEY" required="true" description="Google AI API key (for gemini provider)" />
        <variable name="GEMINI_MODEL" default="gemini-1.5-flash-latest" description="Gemini model name (for gemini provider)" />
      </environment-variables>

      <error-handling>
        <pattern name="Connection Failure">
          <trigger>LLM service unavailable (network error, server down)</trigger>
          <response>Catch error, log details, throw user-friendly error message</response>
          <example>
            Error: Could not connect to Ollama service at http://localhost:11434.

            Please ensure Ollama is running:
            1. Start Ollama: Run `ollama serve` in a terminal
            2. Verify the service: Open http://localhost:11434 in a browser
            3. Check OLLAMA_BASE_URL in .env.local matches the running service
          </example>
        </pattern>
        <pattern name="Model Not Found">
          <trigger>Specified model not available in provider</trigger>
          <response>Throw error with instructions to pull/install model</response>
          <example>
            Error: Model 'llama3.2' not found in Ollama.

            Please pull the model:
            1. Run: `ollama pull llama3.2`
            2. Verify: `ollama list` to see installed models
            3. Update OLLAMA_MODEL in .env.local if using a different model
          </example>
        </pattern>
      </error-handling>
    </reference>

    <reference name="Story 3.1: YouTube API Client Error Handling">
      <description>Reference error handling patterns from YouTube client implementation</description>

      <error-class language="typescript">
        <![CDATA[
/**
 * YouTube API error codes
 */
export enum YouTubeErrorCode {
  API_KEY_NOT_CONFIGURED = 'YOUTUBE_API_KEY_NOT_CONFIGURED',
  API_KEY_INVALID = 'YOUTUBE_API_KEY_INVALID',
  QUOTA_EXCEEDED = 'YOUTUBE_QUOTA_EXCEEDED',
  RATE_LIMITED = 'YOUTUBE_RATE_LIMITED',
  NETWORK_ERROR = 'YOUTUBE_NETWORK_ERROR',
  INVALID_REQUEST = 'YOUTUBE_INVALID_REQUEST',
  SERVICE_UNAVAILABLE = 'YOUTUBE_SERVICE_UNAVAILABLE'
}

/**
 * Custom error class for YouTube API errors
 */
export class YouTubeError extends Error {
  constructor(
    public code: YouTubeErrorCode,
    message: string,
    public context?: Record<string, any>
  ) {
    super(message);
    this.name = 'YouTubeError';

    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, YouTubeError);
    }
  }

  toJSON(): object {
    return {
      name: this.name,
      code: this.code,
      message: this.message,
      context: this.context,
      stack: this.stack
    };
  }
}
        ]]>
      </error-class>

      <error-handling-pattern>
        <principle>Actionable error messages with context</principle>
        <principle>Structured error codes for programmatic handling</principle>
        <principle>Preserve error context for debugging</principle>
        <principle>User-friendly messages with resolution guidance</principle>
      </error-handling-pattern>
    </reference>

    <reference name="Story 3.1: YouTube Types">
      <description>Type definitions for YouTube integration, reference pattern for SceneAnalysis types</description>

      <type-definitions language="typescript">
        <![CDATA[
/**
 * Video search result from YouTube API
 */
export interface VideoResult {
  videoId: string;
  title: string;
  thumbnailUrl: string;
  channelTitle: string;
  embedUrl: string;
  publishedAt: string;
  description: string;
  viewCount?: number;
  likeCount?: number;
  duration?: string;
}

/**
 * Search options for YouTube video queries
 */
export interface SearchOptions {
  maxResults?: number;
  relevanceLanguage?: string;
  videoEmbeddable?: boolean;
  videoDuration?: 'short' | 'medium' | 'long';
  order?: 'relevance' | 'date' | 'viewCount' | 'rating';
}

/**
 * Quota usage tracking information
 */
export interface QuotaUsage {
  used: number;
  limit: number;
  remaining: number;
  resetTime: Date;
}
        ]]>
      </type-definitions>

      <pattern-notes>
        - All interfaces exported for reusability
        - Optional fields marked with ?
        - Enums for constrained string values
        - Clear JSDoc comments on all types
        - Interfaces organized in single types.ts file
      </pattern-notes>
    </reference>
  </reference-implementations>

  <database-schema>
    <table name="scenes">
      <description>Stores script scenes with text and audio file paths</description>
      <schema language="sql">
        <![CDATA[
CREATE TABLE scenes (
  id TEXT PRIMARY KEY,
  project_id TEXT NOT NULL,
  scene_number INTEGER NOT NULL,
  text TEXT NOT NULL,              -- Original script text from LLM
  sanitized_text TEXT,             -- Cleaned text for TTS input
  audio_file_path TEXT,            -- Path to generated MP3 voiceover
  duration REAL,                   -- Audio duration in seconds
  created_at TEXT DEFAULT (datetime('now')),
  FOREIGN KEY (project_id) REFERENCES projects(id) ON DELETE CASCADE
);

CREATE INDEX idx_scenes_project_id ON scenes(project_id);
CREATE INDEX idx_scenes_scene_number ON scenes(project_id, scene_number);
        ]]>
      </schema>

      <query-patterns language="typescript">
        <![CDATA[
// Get all scenes for a project (ordered by scene_number)
const scenes = db.prepare(`
  SELECT id, project_id, scene_number, text, sanitized_text, audio_file_path, duration
  FROM scenes
  WHERE project_id = ?
  ORDER BY scene_number ASC
`).all(projectId);

// Get single scene by ID
const scene = db.prepare(`
  SELECT id, project_id, scene_number, text, sanitized_text, audio_file_path, duration
  FROM scenes
  WHERE id = ?
`).get(sceneId);

// Insert new scene
db.prepare(`
  INSERT INTO scenes (id, project_id, scene_number, text, sanitized_text)
  VALUES (?, ?, ?, ?, ?)
`).run(sceneId, projectId, sceneNumber, text, sanitizedText);
        ]]>
      </query-patterns>

      <usage-notes>
        - scene.text contains the original narration text from LLM script generation
        - scene.text is the input for analyzeSceneForVisuals() function
        - Scene text may contain markdown (*, #, etc.) - should be sanitized before TTS
        - For this story, we only READ scene.text - no database writes required
        - Story 3.3 will write visual_suggestions linked to scene.id
      </usage-notes>
    </table>

    <table name="projects">
      <description>Project metadata including workflow state</description>
      <relevant-fields>
        <field name="id" type="TEXT PRIMARY KEY" description="Project unique identifier" />
        <field name="topic" type="TEXT" description="Confirmed video topic from Epic 1" />
        <field name="voice_id" type="TEXT" description="Selected TTS voice from Epic 2" />
        <field name="current_step" type="TEXT" description="Workflow state: 'visual-sourcing' during this story" />
        <field name="visuals_generated" type="BOOLEAN" description="Set to true after Story 3.5 completes" />
      </relevant-fields>
    </table>
  </database-schema>

  <architecture-patterns>
    <pattern name="LLM Provider Abstraction">
      <principle>Strategy Pattern for runtime provider selection</principle>
      <principle>Factory Pattern for provider instantiation</principle>
      <principle>Dependency Injection via factory function</principle>
      <implementation>
        - Use createLLMProvider() factory function (never instantiate providers directly)
        - Provider choice based on LLM_PROVIDER environment variable
        - All LLM calls through LLMProvider interface (provider-agnostic)
        - Error handling abstracted at provider level
      </implementation>
    </pattern>

    <pattern name="Prompt Engineering">
      <principle>Separation of prompt templates from logic</principle>
      <principle>Parameterized templates with variable substitution</principle>
      <principle>Structured output specification (JSON format)</principle>
      <implementation>
        - Store prompts as constants in lib/llm/prompts/ directory
        - Use string template literals with ${variable} substitution
        - Specify JSON output format explicitly in prompt
        - Include examples in prompt for few-shot learning
        - Document prompt purpose and expected output in JSDoc
      </implementation>
    </pattern>

    <pattern name="Fallback Logic">
      <principle>Graceful degradation when LLM unavailable</principle>
      <principle>Deterministic fallback for system resilience</principle>
      <implementation>
        - Primary path: LLM-based analysis (high quality)
        - Fallback path: Keyword extraction (lower quality but always works)
        - Trigger fallback on: connection errors, timeouts, invalid responses
        - Log fallback usage for monitoring
        - Return same SceneAnalysis interface from both paths
      </implementation>
    </pattern>

    <pattern name="Error Handling">
      <principle>Actionable error messages with context</principle>
      <principle>Structured error codes for programmatic handling</principle>
      <principle>Retry logic for transient failures</principle>
      <implementation>
        - Catch all LLM provider errors
        - Classify errors as retryable (empty response, timeout) or non-retryable (invalid JSON)
        - Retry once for retryable errors with 1 second delay
        - Log all errors with context (scene text, LLM response, attempt number)
        - Throw custom error types or fall back to keyword extraction
      </implementation>
    </pattern>

    <pattern name="Performance Optimization">
      <principle>Timeout constraints prevent blocking</principle>
      <principle>Performance monitoring for optimization</principle>
      <implementation>
        - 5 second performance target (average)
        - 10 second timeout for LLM calls (trigger fallback)
        - Log duration of each analysis call
        - Warn if analysis exceeds 5 seconds
        - No caching in MVP (future enhancement)
      </implementation>
    </pattern>
  </architecture-patterns>

  <technical-requirements>
    <requirement id="1" priority="critical">
      <title>Create SceneAnalysis TypeScript Interface</title>
      <file>lib/youtube/types.ts</file>
      <details>
        - Define SceneAnalysis interface with all fields (mainSubject, setting, mood, action, keywords, primaryQuery, alternativeQueries, contentType)
        - Define ContentType enum with values: GAMEPLAY, TUTORIAL, NATURE, B_ROLL, DOCUMENTARY, URBAN, ABSTRACT
        - Export types for use in other modules
        - Add comprehensive JSDoc comments
        - Follow TypeScript best practices (strict mode compliance)
      </details>
      <example language="typescript">
        <![CDATA[
export interface SceneAnalysis {
  /** Primary visual subject (e.g., "lion") */
  mainSubject: string;
  /** Location/environment (e.g., "savanna") */
  setting: string;
  /** Atmosphere/tone (e.g., "sunset", "peaceful") */
  mood: string;
  /** Key action/movement (e.g., "roaming", "walking") */
  action: string;
  /** Additional relevant keywords */
  keywords: string[];
  /** Best search query (4-6 keywords) */
  primaryQuery: string;
  /** 2-3 alternative queries */
  alternativeQueries: string[];
  /** Scene category for filtering */
  contentType: ContentType;
}

export enum ContentType {
  GAMEPLAY = 'gameplay',
  TUTORIAL = 'tutorial',
  NATURE = 'nature',
  B_ROLL = 'b-roll',
  DOCUMENTARY = 'documentary',
  URBAN = 'urban',
  ABSTRACT = 'abstract'
}
        ]]>
      </example>
    </requirement>

    <requirement id="2" priority="critical">
      <title>Create Visual Search Prompt Template</title>
      <file>lib/llm/prompts/visual-search-prompt.ts</file>
      <details>
        - Create VISUAL_SEARCH_PROMPT constant as template string
        - Include role definition: "You are a visual content researcher helping to find B-roll footage on YouTube"
        - Add clear instructions for extracting: subject, setting, mood, action, keywords
        - Specify rules: focus on visual elements, use concrete keywords, translate abstract concepts
        - Provide good/bad examples in prompt
        - Specify JSON output format with all required fields
        - Add parameter placeholder: {sceneText} for dynamic injection
        - Implement buildVisualSearchPrompt(sceneText: string) function to substitute variables
        - Add comprehensive JSDoc documentation
      </details>
      <example language="typescript">
        <![CDATA[
export const VISUAL_SEARCH_PROMPT = `
You are a visual content researcher helping to find B-roll footage on YouTube.

TASK: Analyze the scene text and extract visual elements to generate YouTube search queries.

SCENE TEXT:
{sceneText}

INSTRUCTIONS:
1. Identify the MAIN SUBJECT (person, animal, object, concept)
2. Identify the SETTING (location, environment, time)
3. Identify the MOOD (atmosphere, lighting, emotion)
4. Identify the ACTION (what is happening, movement)
5. Extract KEYWORDS (concrete visual elements, not abstract concepts)
6. Generate PRIMARY QUERY (4-6 most relevant keywords for YouTube)
7. Generate 2-3 ALTERNATIVE QUERIES (different keyword combinations, synonyms)
8. Classify CONTENT TYPE (gameplay, tutorial, nature, b-roll, documentary, urban, abstract)

RULES:
- Focus on VISUAL elements (what you can SEE in a video)
- Use concrete keywords, not abstract concepts
- For abstract concepts, suggest visual metaphors (e.g., "success" → "mountain summit celebration")
- Primary query should be the MOST relevant combination
- Alternative queries should provide DIVERSITY (different angles, synonyms)
- Keywords should be YouTube search optimized (popular search terms)
- Exclude filler words (the, a, is, in) from queries

EXAMPLES:

Good Analysis:
Scene: "A majestic lion roams the savanna at sunset"
mainSubject: "lion"
setting: "savanna"
mood: "sunset"
action: "roaming"
keywords: ["wildlife", "grassland", "golden hour", "majestic"]
primaryQuery: "lion savanna sunset wildlife"
alternativeQueries: ["african lion sunset", "lion walking grassland golden hour"]
contentType: "nature"

Bad Analysis:
Scene: "The concept of innovation drives progress"
mainSubject: "innovation" ❌ (too abstract)
Better: "lightbulb moment idea" ✅ (visual metaphor)

OUTPUT FORMAT (JSON only, no other text):
{
  "mainSubject": "...",
  "setting": "...",
  "mood": "...",
  "action": "...",
  "keywords": ["...", "..."],
  "primaryQuery": "...",
  "alternativeQueries": ["...", "..."],
  "contentType": "..."
}
`;

export function buildVisualSearchPrompt(sceneText: string): string {
  return VISUAL_SEARCH_PROMPT.replace('{sceneText}', sceneText);
}
        ]]>
      </example>
    </requirement>

    <requirement id="3" priority="critical">
      <title>Implement Fallback Keyword Extraction</title>
      <file>lib/youtube/keyword-extractor.ts</file>
      <details>
        - Implement extractKeywords(sceneText: string): string[] function
        - Tokenize text (split on whitespace and punctuation)
        - Convert to lowercase
        - Filter words shorter than 4 characters
        - Remove stop words (the, a, and, in, etc.) - maintain list of ~30 common words
        - Count word frequency
        - Sort by frequency descending
        - Return top 5 keywords
        - Implement createFallbackAnalysis(sceneText: string): SceneAnalysis function
        - Construct minimal but valid SceneAnalysis from keywords
        - Set contentType to ContentType.B_ROLL as safe default
        - Add comprehensive JSDoc comments
      </details>
      <example language="typescript">
        <![CDATA[
const stopWords = new Set([
  'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at',
  'to', 'for', 'of', 'with', 'by', 'from', 'as', 'is', 'was',
  'are', 'been', 'being', 'have', 'has', 'had', 'do', 'does',
  'did', 'will', 'would', 'should', 'could', 'may', 'might',
  'this', 'that', 'these', 'those', 'then', 'than', 'such'
]);

export function extractKeywords(sceneText: string): string[] {
  // Tokenize
  const words = sceneText
    .toLowerCase()
    .replace(/[^\w\s]/g, ' ')
    .split(/\s+/)
    .filter(word => word.length > 3);

  // Remove stop words
  const keywords = words.filter(word => !stopWords.has(word));

  // Frequency counting
  const frequency = new Map<string, number>();
  keywords.forEach(word => {
    frequency.set(word, (frequency.get(word) || 0) + 1);
  });

  // Sort by frequency, return top 5
  return Array.from(frequency.entries())
    .sort((a, b) => b[1] - a[1])
    .slice(0, 5)
    .map(([word]) => word);
}

export function createFallbackAnalysis(sceneText: string): SceneAnalysis {
  const keywords = extractKeywords(sceneText);
  const primaryQuery = keywords.slice(0, 4).join(' ');

  return {
    mainSubject: keywords[0] || '',
    setting: keywords[1] || '',
    mood: '',
    action: '',
    keywords: keywords,
    primaryQuery: primaryQuery,
    alternativeQueries: [],
    contentType: ContentType.B_ROLL
  };
}
        ]]>
      </example>
    </requirement>

    <requirement id="4" priority="critical">
      <title>Implement Core analyzeSceneForVisuals() Function</title>
      <file>lib/youtube/analyze-scene.ts</file>
      <details>
        - Import dependencies: createLLMProvider, buildVisualSearchPrompt, createFallbackAnalysis, SceneAnalysis, ContentType
        - Implement analyzeSceneForVisuals(sceneText: string): Promise&lt;SceneAnalysis&gt; function
        - Step 1: Input validation (check sceneText is non-empty string, trim whitespace, throw error if empty)
        - Step 2: Build LLM prompt (call buildVisualSearchPrompt(sceneText))
        - Step 3: Call LLM provider with timeout (10 seconds)
        - Step 4: Parse and validate LLM response (JSON.parse, check required fields)
        - Step 5: Handle LLM errors with retry logic (1 retry for empty/missing fields, immediate fallback for invalid JSON)
        - Step 6: Return SceneAnalysis object (success: parsed LLM response, fallback: createFallbackAnalysis(sceneText))
        - Add comprehensive logging (start, duration, success/error, fallback usage)
        - Add JSDoc documentation with examples
      </details>
      <example language="typescript">
        <![CDATA[
import { createLLMProvider } from '../llm/factory';
import { buildVisualSearchPrompt } from '../llm/prompts/visual-search-prompt';
import { createFallbackAnalysis } from './keyword-extractor';
import type { SceneAnalysis, ContentType } from './types';

export async function analyzeSceneForVisuals(sceneText: string): Promise<SceneAnalysis> {
  const startTime = Date.now();

  // Input validation
  if (!sceneText || sceneText.trim().length === 0) {
    throw new Error('Scene text cannot be empty');
  }

  const cleanText = sceneText.trim();
  console.log(`[SceneAnalyzer] Analyzing scene: "${cleanText.substring(0, 50)}..."`);

  try {
    // Build prompt
    const prompt = buildVisualSearchPrompt(cleanText);

    // Get LLM provider
    const llm = createLLMProvider();

    // Call LLM with timeout
    const timeoutPromise = new Promise<never>((_, reject) =>
      setTimeout(() => reject(new Error('LLM_TIMEOUT')), 10000)
    );

    const llmPromise = llm.chat([{ role: 'user', content: prompt }]);
    const response = await Promise.race([llmPromise, timeoutPromise]);

    // Parse JSON response
    const analysis = JSON.parse(response);

    // Validate required fields
    if (!analysis.mainSubject || !analysis.primaryQuery) {
      console.warn('[SceneAnalyzer] Missing required fields, retrying...');
      // Retry once
      const retryResponse = await Promise.race([llm.chat([{ role: 'user', content: prompt }]), timeoutPromise]);
      const retryAnalysis = JSON.parse(retryResponse);

      if (!retryAnalysis.mainSubject || !retryAnalysis.primaryQuery) {
        console.warn('[SceneAnalyzer] Retry failed, using fallback');
        return createFallbackAnalysis(cleanText);
      }

      const duration = Date.now() - startTime;
      console.log(`[SceneAnalyzer] Analysis completed in ${duration}ms (after retry)`);
      return retryAnalysis as SceneAnalysis;
    }

    const duration = Date.now() - startTime;
    console.log(`[SceneAnalyzer] Analysis completed in ${duration}ms`);
    console.log(`[SceneAnalyzer] Primary query: "${analysis.primaryQuery}"`);

    if (duration > 5000) {
      console.warn(`[SceneAnalyzer] WARNING: Analysis slow (${duration}ms). Consider LLM performance tuning.`);
    }

    return analysis as SceneAnalysis;

  } catch (error: any) {
    const duration = Date.now() - startTime;

    if (error.message === 'LLM_TIMEOUT') {
      console.warn(`[SceneAnalyzer] LLM timeout after 10s, using fallback`);
    } else if (error instanceof SyntaxError) {
      console.warn(`[SceneAnalyzer] Invalid JSON response, using fallback`);
    } else {
      console.error(`[SceneAnalyzer] LLM error:`, error.message);
    }

    console.log(`[SceneAnalyzer] Fallback analysis completed in ${duration}ms`);
    return createFallbackAnalysis(cleanText);
  }
}
        ]]>
      </example>
    </requirement>

    <requirement id="5" priority="high">
      <title>Add Performance Monitoring and Logging</title>
      <details>
        - Track performance timing (Date.now() before/after analysis)
        - Log performance metrics (success: duration, timeout: 10000ms, fallback: duration)
        - Add performance warning if analysis &gt;5s
        - Track analysis method used (LLM vs fallback)
        - Add structured logging format with module, function, sceneTextPreview, method, duration, success, primaryQuery, timestamp
        - Implement log levels: INFO (successful analysis), WARN (slow analysis, retry), ERROR (LLM failures, fallback)
        - Support environment variable for log level control: YOUTUBE_LOG_LEVEL
      </details>
    </requirement>

    <requirement id="6" priority="high">
      <title>Handle Various Scene Types</title>
      <details>
        - Enhance visual search prompt with scene type examples
        - Add examples for: Nature, Gaming, Tutorial, Urban, Abstract
        - Test with diverse scene types to validate extraction accuracy
        - Document scene type handling in JSDoc comments
        - Ensure contentType classification accuracy
      </details>
      <scene-type-examples>
        <example type="nature">
          <input>A majestic lion roams the savanna at sunset</input>
          <expected-output>
            mainSubject: "lion"
            setting: "savanna"
            mood: "sunset"
            action: "roaming"
            contentType: "nature"
            primaryQuery: "lion savanna sunset wildlife"
          </expected-output>
        </example>
        <example type="gaming">
          <input>A player navigates through a dark forest in Minecraft</input>
          <expected-output>
            mainSubject: "minecraft gameplay"
            setting: "dark forest"
            action: "navigating"
            contentType: "gameplay"
            primaryQuery: "minecraft dark forest gameplay"
          </expected-output>
        </example>
        <example type="tutorial">
          <input>Mix flour and eggs in a glass bowl</input>
          <expected-output>
            mainSubject: "mixing ingredients"
            setting: "kitchen"
            action: "mixing"
            contentType: "tutorial"
            primaryQuery: "mixing flour eggs bowl tutorial"
          </expected-output>
        </example>
        <example type="urban">
          <input>The busy streets of Tokyo at night glow with neon signs</input>
          <expected-output>
            mainSubject: "tokyo streets"
            setting: "night city"
            mood: "neon lights"
            contentType: "urban"
            primaryQuery: "tokyo night neon streets"
          </expected-output>
        </example>
        <example type="abstract">
          <input>Innovation drives technological progress</input>
          <expected-output>
            mainSubject: "lightbulb moment idea"
            setting: "modern lab"
            contentType: "abstract"
            primaryQuery: "innovation technology lightbulb ideas"
          </expected-output>
        </example>
      </scene-type-examples>
    </requirement>
  </technical-requirements>

  <testing-requirements>
    <unit-tests file="tests/unit/scene-analyzer.test.ts">
      <test name="Input validation - empty string throws error">
        <description>Verify that analyzeSceneForVisuals() throws error for empty input</description>
      </test>
      <test name="LLM success case - returns valid SceneAnalysis">
        <description>Mock LLM provider to return valid JSON, verify SceneAnalysis structure</description>
      </test>
      <test name="LLM timeout triggers fallback">
        <description>Mock LLM to delay &gt;10s, verify fallback keyword extraction used</description>
      </test>
      <test name="Empty LLM response triggers retry then fallback">
        <description>Mock LLM to return empty string, verify retry attempt, then fallback</description>
      </test>
      <test name="Invalid JSON triggers fallback immediately">
        <description>Mock LLM to return non-JSON text, verify immediate fallback (no retry)</description>
      </test>
      <test name="Missing required fields trigger retry">
        <description>Mock LLM to return JSON without mainSubject, verify retry attempt</description>
      </test>
      <test name="Retry succeeds on second attempt">
        <description>Mock LLM to fail first call but succeed on retry, verify success</description>
      </test>
      <test name="Performance logging - duration tracked">
        <description>Verify that analysis duration is logged correctly</description>
      </test>
    </unit-tests>

    <unit-tests file="tests/unit/keyword-extractor.test.ts">
      <test name="extractKeywords() with sample text">
        <description>Test keyword extraction with known input, verify top 5 keywords</description>
      </test>
      <test name="Stop word removal">
        <description>Verify that common stop words are filtered out</description>
      </test>
      <test name="Frequency sorting">
        <description>Verify that keywords are sorted by frequency descending</description>
      </test>
      <test name="Top 5 keyword selection">
        <description>Verify that only top 5 keywords are returned</description>
      </test>
      <test name="createFallbackAnalysis() structure">
        <description>Verify that fallback returns valid SceneAnalysis object</description>
      </test>
      <test name="Fallback with short text (&lt;10 words)">
        <description>Test fallback behavior with minimal input</description>
      </test>
      <test name="Fallback with long text (&gt;200 words)">
        <description>Test fallback behavior with extensive input</description>
      </test>
      <test name="Fallback with text containing only stop words">
        <description>Verify graceful handling of degenerate input</description>
      </test>
    </unit-tests>

    <unit-tests file="tests/unit/visual-search-prompt.test.ts">
      <test name="buildVisualSearchPrompt() parameterization">
        <description>Verify that {sceneText} placeholder is replaced correctly</description>
      </test>
      <test name="Prompt includes scene text">
        <description>Verify that built prompt contains the input scene text</description>
      </test>
      <test name="Prompt format validation">
        <description>Verify prompt structure (role, instructions, examples, output format)</description>
      </test>
    </unit-tests>

    <integration-tests file="tests/integration/scene-analysis.test.ts">
      <test name="Real LLM integration with Ollama">
        <description>Test with actual Ollama provider (if available), verify response structure</description>
      </test>
      <test name="Real LLM integration with Gemini">
        <description>Test with actual Gemini provider (if API key configured), verify response structure</description>
      </test>
      <test name="Various scene types">
        <description>Test with nature, gaming, tutorial, urban, abstract scenes - verify contentType accuracy</description>
      </test>
      <test name="Actual LLM response time">
        <description>Measure real LLM latency, verify &lt;5s average</description>
      </test>
      <test name="SceneAnalysis structure compatibility">
        <description>Verify returned object matches SceneAnalysis interface</description>
      </test>
      <test name="Fallback when LLM unavailable">
        <description>Disable LLM provider, verify fallback produces valid results</description>
      </test>
    </integration-tests>

    <manual-testing>
      <test>Test with local Ollama (Llama 3.2 model)</test>
      <test>Test with cloud Gemini (if API key available)</test>
      <test>Test 5 nature scenes - verify animal/landscape extraction</test>
      <test>Test 5 gaming scenes - verify game/gameplay detection</test>
      <test>Test 5 tutorial scenes - verify subject/tool extraction</test>
      <test>Test 3 abstract scenes - verify metaphor translation</test>
      <test>Disconnect LLM - verify fallback works</test>
      <test>Measure analysis time for 10 scenes (average &lt;5s?)</test>
      <test>Trigger timeout manually (delay LLM response) - verify fallback</test>
      <test>Review LLM logs for errors and warnings</test>
    </manual-testing>
  </testing-requirements>

  <dependencies>
    <dependency type="required" story="Epic 1 Story 1.3">
      <name>LLM Provider Abstraction</name>
      <provides>
        - LLMProvider interface (lib/llm/provider.ts)
        - createLLMProvider() factory function (lib/llm/factory.ts)
        - OllamaProvider implementation (lib/llm/ollama-provider.ts)
        - GeminiProvider implementation (lib/llm/gemini-provider.ts)
        - LLM_PROVIDER environment variable configuration
      </provides>
    </dependency>

    <dependency type="required" story="Epic 2 Story 2.2">
      <name>Database Schema Updates</name>
      <provides>
        - Scenes table with scene text field
        - Database query functions to retrieve scene text
      </provides>
    </dependency>

    <dependency type="optional" story="Story 3.1">
      <name>YouTube API Client Setup</name>
      <provides>
        - YouTube API infrastructure (not used directly in this story)
        - Project structure for lib/youtube/ directory
      </provides>
    </dependency>

    <dependency type="provides-for" story="Story 3.3">
      <name>YouTube Video Search &amp; Result Retrieval</name>
      <consumes>
        - analyzeSceneForVisuals() function to generate search queries
        - SceneAnalysis object structure with primaryQuery and alternativeQueries
        - ContentType classification for filtering logic
      </consumes>
    </dependency>

    <dependency type="provides-for" story="Story 3.4">
      <name>Content Filtering &amp; Quality Ranking</name>
      <consumes>
        - ContentType enum for specialized filtering rules
        - Keywords array for relevance scoring
      </consumes>
    </dependency>

    <external-dependencies>
      <dependency name="Ollama" type="LLM Provider (Primary)">
        <description>Local LLM server running at localhost:11434</description>
        <requirement>Ollama server running with Llama 3.2 (3B) model pulled</requirement>
      </dependency>
      <dependency name="Google Gemini" type="LLM Provider (Optional)">
        <description>Cloud-based LLM with free tier (1,500 requests/day)</description>
        <requirement>GEMINI_API_KEY configured in environment (optional)</requirement>
      </dependency>
    </external-dependencies>
  </dependencies>

  <effort-estimate>
    <total-hours>17</total-hours>
    <breakdown>
      <task name="Task 1: Type Definitions" hours="0.5" />
      <task name="Task 2: Prompt Template" hours="2" />
      <task name="Task 3: Keyword Extraction" hours="2.5" />
      <task name="Task 4: Core Scene Analysis" hours="4" />
      <task name="Task 5: Performance Monitoring" hours="1.5" />
      <task name="Task 6: Scene Type Handling" hours="2" />
      <task name="Task 7: Integration Testing" hours="3" />
      <task name="Task 8: Documentation Updates" hours="1.5" />
    </breakdown>
    <complexity-factors>
      <factor>Medium complexity (reuses existing LLM infrastructure)</factor>
      <factor>Prompt engineering requires iteration for optimal results</factor>
      <factor>Fallback logic adds error handling complexity</factor>
      <factor>Testing across multiple scene types requires diverse test cases</factor>
    </complexity-factors>
    <risk-areas>
      <risk>LLM prompt may require tuning based on actual results</risk>
      <risk>Fallback keyword extraction may be too simplistic for complex scenes</risk>
      <risk>Performance variability between Ollama and Gemini providers</risk>
    </risk-areas>
  </effort-estimate>

  <implementation-notes>
    <note category="Design Decisions">
      <title>Why LLM for Scene Analysis?</title>
      <rationale>
        - Understands context and semantics beyond keyword matching
        - Can translate abstract concepts into visual metaphors
        - Generates diverse query variations (synonyms, different angles)
        - Already integrated in project (Epic 1), no new dependencies
        - Provides natural language understanding for complex scenes
      </rationale>
    </note>

    <note category="Design Decisions">
      <title>Why Simple Keyword Extraction for Fallback?</title>
      <rationale>
        - No external NLP library dependencies (keeps project lightweight)
        - Fast performance (&lt;100ms) for uninterrupted workflow
        - Sufficient quality for basic visual sourcing (frequency-based relevance)
        - Robust (always works, even with poor input)
        - Acceptable trade-off: Lower quality but 100% availability
      </rationale>
    </note>

    <note category="Design Decisions">
      <title>Why 2-3 Alternative Queries?</title>
      <rationale>
        - Balances result diversity with API quota efficiency
        - More than 3 alternatives = diminishing returns + slower processing
        - Less than 2 alternatives = insufficient diversity for quality results
        - Aligns with YouTube API quota management (Story 3.1)
      </rationale>
    </note>

    <note category="Design Decisions">
      <title>Why 10s Timeout?</title>
      <rationale>
        - LLM target: &lt;5s average (healthy performance)
        - Timeout at 10s: Allows for slow responses without blocking indefinitely
        - Gemini free tier can be slow under high load (up to 10s observed)
        - Ollama local performance usually &lt;3s (generous buffer)
        - After 10s, user experience degrades → Fallback is better than waiting
      </rationale>
    </note>

    <note category="Prompt Engineering">
      <title>Prompt Engineering Strategy</title>
      <techniques>
        1. Role Definition: "You are a visual content researcher" → Sets LLM context
        2. Clear Task: "Extract visual elements to generate YouTube search queries" → Specific goal
        3. Structured Instructions: Numbered steps (1-8) → Reduces ambiguity
        4. Rules Section: Explicit constraints → Prevents common errors (abstract concepts)
        5. Examples (Good/Bad): Shows desired output → Few-shot learning
        6. JSON Format Specification: Structured output → Easy parsing
      </techniques>
      <iteration-guidance>
        If initial results are poor, iterate on prompt with:
        - More examples of edge cases
        - Stricter rules for keyword selection
        - Explicit YouTube search optimization tips
      </iteration-guidance>
    </note>

    <note category="Performance">
      <title>LLM Response Time Variability</title>
      <observations>
        - Ollama (local): 1-3s typical, depends on CPU/GPU
        - Gemini (cloud): 2-5s typical, can spike to 10s under load
        - Scene text length impacts processing (longer = slower)
      </observations>
      <optimization-strategies>
        - Keep prompt concise (reduce token count)
        - Use smaller LLM models for faster responses (Llama 3.2 3B)
        - Consider caching scene analyses (future enhancement)
        - Batch analyze scenes if multiple scenes need processing
      </optimization-strategies>
      <fallback-performance>
        - Keyword extraction: 10-50ms typical
        - No network calls = consistent performance
        - Suitable for real-time user experience
      </fallback-performance>
    </note>

    <note category="Security">
      <title>Security Considerations</title>
      <consideration name="Scene Text Input Sanitization">
        - Scene text comes from database (already validated in Epic 2 Story 2.4)
        - No direct user input to scene analyzer
        - LLM prompt injection risk: Low (scene text is script content, not adversarial)
      </consideration>
      <consideration name="LLM Response Validation">
        - Always validate JSON structure before using
        - Check required fields exist
        - Sanitize contentType enum (use default if invalid)
        - Never execute or eval LLM response code
      </consideration>
      <consideration name="API Key Security">
        - LLM provider API keys already secured in Epic 1 (environment variables)
        - No API keys logged or exposed in analysis logs
      </consideration>
    </note>

    <note category="Future Enhancements">
      <title>Post-MVP Improvements</title>
      <enhancement name="Caching Scene Analyses">
        - Cache SceneAnalysis results by sceneText hash
        - Avoid re-analyzing identical scene text
        - Significant performance improvement for re-runs
      </enhancement>
      <enhancement name="Advanced Keyword Extraction">
        - Use NLP library (natural, compromise) for better fallback quality
        - Part-of-speech tagging for noun/verb identification
        - Named entity recognition for proper nouns
      </enhancement>
      <enhancement name="Query Quality Scoring">
        - Score generated queries for relevance
        - Reject low-quality queries and retry with refined prompt
        - A/B test query variations to optimize YouTube result quality
      </enhancement>
      <enhancement name="Multi-Language Support">
        - Translate scene text to English before analysis
        - Support non-English YouTube searches (relevanceLanguage parameter)
      </enhancement>
      <enhancement name="Content Type Auto-Filtering">
        - Use contentType to auto-select appropriate YouTube filters
        - Gaming → "gameplay" keyword filter
        - Tutorial → "how to" keyword filter
      </enhancement>
    </note>
  </implementation-notes>

  <file-checklist>
    <file path="lib/youtube/types.ts" status="create">
      <description>SceneAnalysis interface and ContentType enum definitions</description>
      <tasks>
        - Define SceneAnalysis interface with all fields
        - Define ContentType enum with 7 values
        - Export types for use in other modules
        - Add JSDoc comments explaining each field
      </tasks>
    </file>

    <file path="lib/llm/prompts/visual-search-prompt.ts" status="create">
      <description>Visual search prompt template for LLM scene analysis</description>
      <tasks>
        - Create VISUAL_SEARCH_PROMPT constant
        - Include role, task, instructions, rules, examples
        - Add {sceneText} placeholder for parameterization
        - Implement buildVisualSearchPrompt(sceneText) function
        - Add comprehensive JSDoc documentation
      </tasks>
    </file>

    <file path="lib/youtube/keyword-extractor.ts" status="create">
      <description>Fallback keyword extraction for when LLM unavailable</description>
      <tasks>
        - Implement extractKeywords(sceneText) function
        - Implement stop word filtering
        - Implement frequency-based sorting
        - Implement createFallbackAnalysis(sceneText) function
        - Add JSDoc documentation
      </tasks>
    </file>

    <file path="lib/youtube/analyze-scene.ts" status="create">
      <description>Main analyzeSceneForVisuals() function with LLM integration</description>
      <tasks>
        - Import all dependencies
        - Implement analyzeSceneForVisuals(sceneText) function
        - Input validation
        - LLM prompt building
        - LLM provider call with timeout
        - Response parsing and validation
        - Retry logic for errors
        - Fallback on failures
        - Performance logging
        - Add comprehensive JSDoc with examples
      </tasks>
    </file>

    <file path="tests/unit/scene-analyzer.test.ts" status="create">
      <description>Unit tests for scene analyzer</description>
      <tasks>
        - Test input validation
        - Test LLM success case
        - Test timeout behavior
        - Test empty response retry
        - Test invalid JSON fallback
        - Test missing fields retry
        - Test retry success
        - Test performance logging
      </tasks>
    </file>

    <file path="tests/unit/keyword-extractor.test.ts" status="create">
      <description>Unit tests for keyword extractor</description>
      <tasks>
        - Test extractKeywords() with sample text
        - Test stop word removal
        - Test frequency sorting
        - Test top 5 selection
        - Test createFallbackAnalysis() structure
        - Test edge cases (short text, long text, stop words only)
      </tasks>
    </file>

    <file path="tests/unit/visual-search-prompt.test.ts" status="create">
      <description>Unit tests for prompt template</description>
      <tasks>
        - Test buildVisualSearchPrompt() parameterization
        - Test scene text inclusion
        - Test prompt format
      </tasks>
    </file>

    <file path="tests/integration/scene-analysis.test.ts" status="create">
      <description>Integration tests with real LLM providers</description>
      <tasks>
        - Test with Ollama provider
        - Test with Gemini provider
        - Test various scene types
        - Test performance measurement
        - Test SceneAnalysis structure
        - Test fallback behavior
      </tasks>
    </file>

    <file path="docs/architecture.md" status="update">
      <description>Update Epic 3 architecture documentation</description>
      <tasks>
        - Document SceneAnalyzer module responsibility
        - Document data flow (Scene Text → LLM → SceneAnalysis)
        - Add code examples for analyzeSceneForVisuals()
        - Document performance considerations
        - Document error handling strategy
        - Add troubleshooting section
        - Update project structure diagram
      </tasks>
    </file>
  </file-checklist>

  <definition-of-done>
    <code-complete>
      <item>lib/youtube/types.ts: SceneAnalysis interface and ContentType enum defined</item>
      <item>lib/llm/prompts/visual-search-prompt.ts: Prompt template implemented</item>
      <item>lib/youtube/keyword-extractor.ts: Fallback extraction functions implemented</item>
      <item>lib/youtube/analyze-scene.ts: analyzeSceneForVisuals() function implemented</item>
      <item>All TypeScript code compiles without errors</item>
      <item>ESLint passes with no warnings</item>
    </code-complete>

    <testing-complete>
      <item>Unit tests written for scene analyzer (&gt;90% coverage)</item>
      <item>Unit tests written for keyword extractor (&gt;90% coverage)</item>
      <item>Integration tests with LLM provider passing</item>
      <item>Manual testing completed for all scene types (nature, gaming, tutorial, urban, abstract)</item>
      <item>Fallback logic tested with LLM disabled</item>
      <item>Performance testing shows &lt;5s average analysis time</item>
      <item>Timeout behavior verified (triggers fallback at 10s)</item>
      <item>Retry logic tested with empty/invalid LLM responses</item>
    </testing-complete>

    <documentation-complete>
      <item>JSDoc comments on all public functions</item>
      <item>Architecture.md updated with SceneAnalyzer module documentation</item>
      <item>Code examples added to documentation</item>
      <item>Troubleshooting guide for LLM performance issues</item>
      <item>Prompt engineering notes documented</item>
    </documentation-complete>

    <quality-checks>
      <item>Code reviewed by peer or architect</item>
      <item>LLM prompt tested with 10+ diverse scene examples</item>
      <item>Fallback quality acceptable for basic visual sourcing</item>
      <item>Error messages clear and actionable</item>
      <item>Logging captures all important events (success, timeout, fallback)</item>
      <item>No hardcoded values (all configuration via constants or env vars)</item>
    </quality-checks>

    <integration-verified>
      <item>createLLMProvider() factory integration working</item>
      <item>Both Ollama and Gemini providers tested</item>
      <item>SceneAnalysis structure compatible with Story 3.3 search function</item>
      <item>ContentType enum ready for Story 3.4 filtering logic</item>
    </integration-verified>

    <acceptance-criteria-validated>
      <item>AC1: Scene analysis extracts visual themes using LLM ✓</item>
      <item>AC2: Primary search query generated ✓</item>
      <item>AC3: Alternative queries provide diversity (2-3 variations) ✓</item>
      <item>AC4: Content type hints classify scenes ✓</item>
      <item>AC5: SceneAnalysis data structure returned ✓</item>
      <item>AC6: LLM analysis completes within 5 seconds ✓</item>
      <item>AC7: System handles various scene types (nature, gaming, tutorial, urban, abstract) ✓</item>
      <item>AC8: Fallback keyword extraction works when LLM unavailable ✓</item>
      <item>AC9: Invalid/empty LLM responses trigger retry or fallback ✓</item>
      <item>AC10: Visual search prompt template optimized ✓</item>
      <item>AC11: Integration with existing LLM provider works ✓</item>
    </acceptance-criteria-validated>

    <ready-for-next-story>
      <item>Story 3.3 can use analyzeSceneForVisuals() to generate search queries</item>
      <item>SceneAnalysis object structure documented and tested</item>
      <item>ContentType enum available for specialized filtering</item>
      <item>Performance acceptable for multi-scene processing</item>
    </ready-for-next-story>
  </definition-of-done>

  <references>
    <document name="Story 3.2 Definition" path="docs/stories/story-3.2.md" />
    <document name="Epic 3 Technical Specification" path="docs/tech-spec-epic-3.md" />
    <document name="Story 1.3 Implementation" path="docs/stories/story-1.3.md" />
    <document name="Story 3.1 Implementation" path="docs/stories/story-3.1.md" />
    <document name="Architecture Documentation" path="docs/architecture.md" />
    <document name="Epic 3 Definition" path="docs/epics.md" section="Epic 3" />
  </references>
</story-context>
